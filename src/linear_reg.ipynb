{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a975d6",
   "metadata": {},
   "source": [
    "# Linear Regression from Scratch: End-to-End Workflow\n",
    "\n",
    "This notebook demonstrates how to implement and evaluate linear regression models from scratch, compare them with scikit-learn's implementations, and explore regularization techniques. Each step is explained with code and commentary for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227ab87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for data manipulation, visualization, and custom linear regression implementation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from linear_regression import LinearRegression\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7292e32",
   "metadata": {},
   "source": [
    "## Load and Inspect Data\n",
    "\n",
    "We begin by loading the housing dataset and inspecting its structure and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a534b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the housing dataset into a pandas DataFrame\n",
    "df = pd.read_csv('../data/housing_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1282ed60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset to inspect its structure\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341e987f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the dataset (number of rows and columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6ee665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude               0\n",
       "latitude                0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        207\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "median_house_value      0\n",
       "ocean_proximity         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cefd9d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Fill missing values in 'total_bedrooms' with the column mean to handle NaNs\n",
    "df[\"total_bedrooms\"].fillna(df[\"total_bedrooms\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c9100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude             0\n",
       "latitude              0\n",
       "housing_median_age    0\n",
       "total_rooms           0\n",
       "total_bedrooms        0\n",
       "population            0\n",
       "households            0\n",
       "median_income         0\n",
       "median_house_value    0\n",
       "ocean_proximity       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that all missing values have been handled\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ac23dd",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We convert categorical columns to numeric using one-hot encoding, separate features and target, and ensure the target is of the correct type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749c7a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical columns to convert them into numeric features\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop('median_house_value', axis=1).values\n",
    "y = df['median_house_value'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cff12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the target variable is of float type for regression\n",
    "y = y.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f67360",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Standardize the features to have zero mean and unit variance, which is important for gradient-based optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a115c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features to have zero mean and unit variance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3f21b3",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "Split the dataset into training and testing sets to evaluate model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d439ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets for model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to numpy arrays and ensure correct data types\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "y_train = y_train.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524db208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 12) (16512,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the training data to verify correct splitting\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a59463d",
   "metadata": {},
   "source": [
    "## Train Custom Linear Regression Model\n",
    "\n",
    "Fit the custom linear regression model using gradient descent on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff5c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the custom LinearRegression model using gradient descent\n",
    "model = LinearRegression(learning_rate=0.01, n_iterations=5000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7fd890",
   "metadata": {},
   "source": [
    "## Compare Custom Linear Regression with Scikit-learn\n",
    "\n",
    "This section directly compares the predictions of the custom `LinearRegression` model (implemented from scratch) with those of scikit-learn's `LinearRegression`. The similarity percentage quantifies how closely the model's predictions match the industry-standard implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare custom LinearRegression with scikit-learn's LinearRegression\n",
    "from linear_regression import LinearRegression  # Custom model\n",
    "from sklearn.linear_model import LinearRegression as SklearnLinearRegression  # Scikit-learn model\n",
    "import numpy as np\n",
    "\n",
    "# Train custom model\n",
    "custom_model = LinearRegression(learning_rate=0.01, n_iterations=5000)\n",
    "custom_model.fit(X_train, y_train)\n",
    "y_pred = custom_model.predict(X_test)\n",
    "\n",
    "# Train scikit-learn model\n",
    "sklearn_model = SklearnLinearRegression()\n",
    "sklearn_model.fit(X_train, y_train)\n",
    "y_sklearn_pred = sklearn_model.predict(X_test)\n",
    "\n",
    "# Calculate prediction similarity (%) between custom and sklearn models\n",
    "pred_similarity = 100 - (np.mean(np.abs(y_pred - y_sklearn_pred)) / np.mean(np.abs(y_sklearn_pred)) * 100)\n",
    "print(f\"Prediction similarity to scikit-learn: {pred_similarity:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb486a",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE)\n",
    "\n",
    "Calculate and compare the Mean Squared Error for both the custom and scikit-learn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d057fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and compare Mean Squared Error (MSE) for both models\n",
    "from metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_squared_error as sk_mse\n",
    "\n",
    "# Custom model MSE\n",
    "mse_custom = mse(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse_custom)\n",
    "\n",
    "# Scikit-learn model MSE\n",
    "mse_sklearn = sk_mse(y_test, y_sklearn_pred)\n",
    "print('Mean Squared Error (Scikit-learn Model):', mse_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d1b61e",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (MAE)\n",
    "\n",
    "Calculate and compare the Mean Absolute Error for both the custom and scikit-learn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a56e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and compare Mean Absolute Error (MAE) for both models\n",
    "from metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_absolute_error as sk_mae\n",
    "\n",
    "# Custom model MAE\n",
    "mae_custom = mae(y_test, y_pred)\n",
    "print('Mean Absolute Error:', mae_custom)\n",
    "\n",
    "# Scikit-learn model MAE\n",
    "mae_sklearn = sk_mae(y_test, y_sklearn_pred)\n",
    "print('Mean Absolute Error (Scikit-learn Model):', mae_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cab533",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error (RMSE)\n",
    "\n",
    "Calculate and compare the Root Mean Squared Error for both the custom and scikit-learn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ddb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and compare Root Mean Squared Error (RMSE) for both models\n",
    "from metrics import root_mean_squared_error as rmse\n",
    "from sklearn.metrics import mean_squared_error as sk_mse\n",
    "\n",
    "# Custom model RMSE\n",
    "rmse_custom = rmse(y_test, y_pred)\n",
    "print('Root Mean Squared Error:', rmse_custom)\n",
    "\n",
    "# Scikit-learn model RMSE\n",
    "rmse_sklearn = np.sqrt(sk_mse(y_test, y_sklearn_pred))\n",
    "print('Root Mean Squared Error (Scikit-learn Model):', rmse_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7747b5",
   "metadata": {},
   "source": [
    "### R2 Score\n",
    "\n",
    "Calculate and compare the R2 Score for both the custom and scikit-learn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d21ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and compare R2 Score for both models\n",
    "from metrics import r2_score as r2\n",
    "from sklearn.metrics import r2_score as sk_r2\n",
    "\n",
    "# Custom model R2\n",
    "r2_custom = r2(y_test, y_pred)\n",
    "print('R2 Score:', r2_custom)\n",
    "\n",
    "# Scikit-learn model R2\n",
    "r2_sklearn = sk_r2(y_test, y_sklearn_pred)\n",
    "print('R2 Score (Scikit-learn Model):', r2_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcde335d",
   "metadata": {},
   "source": [
    "### Metric Similarity\n",
    "\n",
    "Compute similarity percentages for all metrics between custom and scikit-learn models to quantify how close the implementations are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d4f846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity percentages for all metrics between custom and sklearn models\n",
    "mse_accuracy = 100 - (abs(mse_custom - mse_sklearn) / mse_sklearn * 100)\n",
    "print(f\"MSE similarity to scikit-learn: {mse_accuracy:.2f}%\")\n",
    "\n",
    "mae_accuracy = 100 - (abs(mae_custom - mae_sklearn) / mae_sklearn * 100)\n",
    "print(f\"MAE similarity to scikit-learn: {mae_accuracy:.2f}%\")\n",
    "\n",
    "rmse_accuracy = 100 - (abs(rmse_custom - rmse_sklearn) / rmse_sklearn * 100)\n",
    "print(f\"RMSE similarity to scikit-learn: {rmse_accuracy:.2f}%\")\n",
    "\n",
    "r2_accuracy = 100 - (abs(r2_custom - r2_sklearn) / abs(r2_sklearn) * 100)\n",
    "print(f\"R2 similarity to scikit-learn: {r2_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50694ffa",
   "metadata": {},
   "source": [
    "## 🔧 Utility Functions for Linear Regression (from Scratch)\n",
    "\n",
    "This notebook contains helper functions used across the project for:\n",
    "- Data preprocessing (splitting, normalizing, standardizing)\n",
    "- Model input preparation (bias term addition)\n",
    "- Evaluation visualization (predicted vs actual plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6355e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear_regression import LinearRegression  # Custom model\n",
    "from sklearn.linear_model import LinearRegression as SklearnLR  # Actual model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b864ec66",
   "metadata": {},
   "source": [
    "### Train-Test-Split\n",
    "\n",
    "This section contrasts the custom train_test_split function from utils.py with scikit-learn's train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5eb64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare custom and sklearn train_test_split functions for splitting data\n",
    "from utils import train_test_split as custom_train_test_split\n",
    "from sklearn.model_selection import train_test_split as sk_train_test_split\n",
    "\n",
    "# Custom split\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = custom_train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Custom split shapes:\", X_train_c.shape, X_test_c.shape, y_train_c.shape, y_test_c.shape)\n",
    "\n",
    "# Sklearn split\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = sk_train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Sklearn split shapes:\", X_train_s.shape, X_test_s.shape, y_train_s.shape, y_test_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c0d8ac",
   "metadata": {},
   "source": [
    "### Normalize\n",
    "\n",
    "Here, we compare the custom normalize function with scikit-learn's MinMaxScaler. Both scale features to the [0, 1] range, and we check if the results match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f55e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare custom normalize function with sklearn's MinMaxScaler\n",
    "from utils import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Custom normalization\n",
    "X_norm_custom = normalize(X)\n",
    "\n",
    "# Sklearn normalization\n",
    "scaler = MinMaxScaler()\n",
    "X_norm_sklearn = scaler.fit_transform(X)\n",
    "\n",
    "# Compare\n",
    "print(\"Normalization equal:\", np.allclose(X_norm_custom, X_norm_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6581189a",
   "metadata": {},
   "source": [
    "### Standardize\n",
    "\n",
    "This section contrasts the custom standardize function with scikit-learn's StandardScaler. Both standardize features to have zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339dd125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare custom standardize function with sklearn's StandardScaler\n",
    "from utils import standardize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Custom standardization\n",
    "X_std_custom = standardize(X)\n",
    "\n",
    "# Sklearn standardization\n",
    "scaler = StandardScaler()\n",
    "X_std_sklearn = scaler.fit_transform(X)\n",
    "\n",
    "# Compare\n",
    "print(\"Standardization equal:\", np.allclose(X_std_custom, X_std_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0148dabe",
   "metadata": {},
   "source": [
    "### Add-Bias\n",
    "\n",
    "Here, we compare the custom add_bias function with manual bias addition using NumPy. Both add a column of ones to the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63193335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare custom add_bias function with manual bias addition using numpy\n",
    "from utils import add_bias\n",
    "\n",
    "# Custom add_bias\n",
    "X_bias_custom = add_bias(X)\n",
    "\n",
    "# Manual bias addition (like sklearn's LinearRegression(fit_intercept=False))\n",
    "X_bias_manual = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "# Compare\n",
    "print(\"Bias addition equal:\", np.allclose(X_bias_custom, X_bias_manual))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e2774d",
   "metadata": {},
   "source": [
    "### Plot Predictions\n",
    "\n",
    "This section visualizes predictions from both the custom and scikit-learn models using the custom plot_predictions function, allowing a visual comparison of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c687eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions from both custom and sklearn models using the custom plot_predictions function\n",
    "from utils import plot_predictions\n",
    "\n",
    "# Custom plot\n",
    "plot_predictions(y_test, y_pred, title=\"Custom Model: Predicted vs Actual\")\n",
    "\n",
    "# Sklearn model plot\n",
    "plot_predictions(y_test, y_sklearn_pred, title=\"Sklearn Model: Predicted vs Actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f33f57c",
   "metadata": {},
   "source": [
    "## Regularization Techniques for Linear Models (from Scratch)\n",
    "\n",
    "Explore and compare custom implementations of Ridge, Lasso, and ElasticNet regression with their scikit-learn counterparts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923147bd",
   "metadata": {},
   "source": [
    "### Contrasting Custom Ridge Regression with Scikit-learn Ridge Regression\n",
    "\n",
    "This section compares the custom `RidgeRegression` implementation with scikit-learn's `Ridge` model. Both models are trained on the same data (with bias added), and their predictions are compared to evaluate the effect of L2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3109404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare custom RidgeRegression with sklearn's Ridge model (L2 regularization)\n",
    "from regularized_regression import RidgeRegression  # Custom Ridge\n",
    "from sklearn.linear_model import Ridge  # Scikit-learn Ridge\n",
    "import numpy as np\n",
    "\n",
    "# Add bias column to features for custom implementation\n",
    "X_train_bias = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
    "X_test_bias = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
    "\n",
    "# Train custom Ridge Regression\n",
    "custom_ridge = RidgeRegression(learning_rate=0.01, n_iters=1000, alpha=0.5)\n",
    "custom_ridge.fit(X_train_bias, y_train)\n",
    "y_pred_custom_ridge = custom_ridge.predict(X_test_bias)\n",
    "\n",
    "# Train scikit-learn Ridge Regression\n",
    "sklearn_ridge = Ridge(alpha=0.5, fit_intercept=True, solver='auto', max_iter=1000)\n",
    "sklearn_ridge.fit(X_train, y_train)\n",
    "y_pred_sklearn_ridge = sklearn_ridge.predict(X_test)\n",
    "\n",
    "# Compare predictions\n",
    "ridge_similarity = 100 - (np.mean(np.abs(y_pred_custom_ridge - y_pred_sklearn_ridge)) / np.mean(np.abs(y_pred_sklearn_ridge)) * 100)\n",
    "print(f\"Ridge Regression prediction similarity to scikit-learn: {ridge_similarity:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50bb771",
   "metadata": {},
   "source": [
    "### Contrasting Custom Lasso Regression with Scikit-learn Lasso Regression\n",
    "\n",
    "This section compares the custom `LassoRegression` implementation with scikit-learn's `Lasso` model. Both models are trained on the same data (with bias added), and their predictions are compared to evaluate the effect of L1 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32a6ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regularized_regression import LassoRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfc4714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression prediction similarity to scikit--learn: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Compare custom LassoRegression with sklearn's Lasso model (L1 regularization)\n",
    "from regularized_regression import LassoRegression  # Custom Lasso\n",
    "from sklearn.linear_model import Lasso  # Scikit-learn Lasso\n",
    "import numpy as np\n",
    "\n",
    "# Add bias column to features for custom implementation\n",
    "X_train_bias = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
    "X_test_bias = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
    "\n",
    "# Train custom Lasso Regression\n",
    "custom_lasso = LassoRegression(alpha=0.5, n_iters=1000)\n",
    "custom_lasso.fit(X_train_bias, y_train)\n",
    "y_pred_custom_lasso = custom_lasso.predict(X_test_bias)\n",
    "\n",
    "# Train scikit-learn Lasso Regression\n",
    "sklearn_lasso = Lasso(alpha=0.5, fit_intercept=True, max_iter=1000)\n",
    "sklearn_lasso.fit(X_train, y_train)\n",
    "y_pred_sklearn_lasso = sklearn_lasso.predict(X_test)\n",
    "\n",
    "# Compare predictions\n",
    "lasso_similarity = 100 - (np.mean(np.abs(y_pred_custom_lasso - y_pred_sklearn_lasso)) / np.mean(np.abs(y_pred_sklearn_lasso)) * 100)\n",
    "print(f\"Lasso Regression prediction similarity to scikit--learn: {lasso_similarity:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76daa757",
   "metadata": {},
   "source": [
    "### Contrasting Custom ElasticNet Regression with Scikit-learn ElasticNet Regression\n",
    "\n",
    "This section compares the custom `ElasticNetRegression` implementation with scikit-learn's `ElasticNet` model. Both models are trained on the same data (with bias added if required), and their predictions are compared to evaluate the effect of combined L1 and L2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ed8650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Regression prediction similarity to scikit-learn: 96.95%\n"
     ]
    }
   ],
   "source": [
    "# Compare custom ElasticNetRegression with sklearn's ElasticNet model (L1 + L2 regularization)\n",
    "from regularized_regression import ElasticNetRegression  # Custom ElasticNet\n",
    "from sklearn.linear_model import ElasticNet  # Scikit-learn ElasticNet\n",
    "\n",
    "# Add bias column to features (if your custom implementation expects it)\n",
    "X_train_bias = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
    "X_test_bias = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
    "\n",
    "# Train custom ElasticNet Regression\n",
    "custom_enet = ElasticNetRegression(learning_rate=0.01, n_iters=1000, alpha=0.5, l1_ratio=0.5)\n",
    "custom_enet.fit(X_train_bias, y_train)\n",
    "y_pred_custom_enet = custom_enet.predict(X_test_bias)\n",
    "\n",
    "# Train scikit-learn ElasticNet Regression\n",
    "sklearn_enet = ElasticNet(alpha=0.5, l1_ratio=0.5, fit_intercept=True, max_iter=1000)\n",
    "sklearn_enet.fit(X_train, y_train)\n",
    "y_pred_sklearn_enet = sklearn_enet.predict(X_test)\n",
    "\n",
    "# Compare predictions\n",
    "enet_similarity = 100 - (np.mean(np.abs(y_pred_custom_enet - y_pred_sklearn_enet)) / np.mean(np.abs(y_pred_sklearn_enet)) * 100)\n",
    "print(f\"ElasticNet Regression prediction similarity to scikit-learn: {enet_similarity:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6246f41",
   "metadata": {},
   "source": [
    "---\n",
    "## 📚 Conclusion & Further Exploration\n",
    "\n",
    "In this notebook, we built linear regression and regularized regression models from scratch, compared them with scikit-learn's implementations, and validated their performance using multiple metrics and visualizations.\n",
    "\n",
    "- You now have a clear understanding of how linear models work under the hood.\n",
    "- The custom implementations closely match the results from industry-standard libraries.\n",
    "- You can extend this workflow to other datasets or experiment with additional regularization techniques.\n",
    "\n",
    "**Happy Learning!**\n",
    "\n",
    "<div style='text-align:right'><sub>Notebook by [Abhishek Upadhyay](https://github.com/abhisheku007)</sub></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
